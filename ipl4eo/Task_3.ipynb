{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b367442-37e4-4aa2-b112-9c5a0deef47e",
   "metadata": {},
   "source": [
    "# Task 3: Evaluate Deforestation through Bitemporal Change Detection\n",
    "\n",
    "In this final task we quantify deforestation in São Félix do Xingu based on bitemporal satellite observations. We use the Sentinel-2 tile T22MCU previously downloaded and visualized in Task 1, and the CNN-based segmentation model from Task 2 for comparison. Our objective is to measure both absolute and relative forest loss between 2018 and 2024. In this task we perform quantitative change detection at the patch level using two complementary approaches:\n",
    "\n",
    "- **NDVI differencing**\n",
    "- **CNN segmentation differencing**\n",
    "\n",
    "The combined evaluation enables us to assess the agreement between physical indices and data-driven model outputs while identifying specific strengths and limitations of both approaches. \n",
    "\n",
    "We focus on tile **T22MCU** which covers one of the most deforested sectors in the municipality and shows strong spatial variability in canopy loss. \n",
    "\n",
    "**Important Note**\n",
    "\n",
    "If you were not able to complete Task 1 or 2, we provide a preprocessed version of the tile and a simple pretrained CNN model for this task. Please use these resources if necessary.\n",
    "The model can be loaded with `model = torch.jit.load(\"backup_model.pt\")`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40679ab6-1339-4287-b19b-f2cd586dd724",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Imports\n",
    "These are all imports we used when solving the task. Please leave them as is even though you might not need all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a49197-1674-4ddb-b92c-bd239401df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rootutils\n",
    "root = rootutils.setup_root(os.path.abspath(''), dotenv=True, pythonpath=True, cwd=False)\n",
    "\n",
    "data_path = root / \"data\"\n",
    "data_path.mkdir(exist_ok=True)\n",
    "output_dir = root / \"output\"\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3742f915-2560-4334-8f4f-a39c309bfdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, Optional\n",
    "from dataclasses import dataclass, field\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2167d70-3771-48d4-b98e-25a129f8b863",
   "metadata": {},
   "source": [
    "## 3.1 Patch Extraction and Preprocessing\n",
    "\n",
    "- Load the tile\n",
    "  \n",
    "- Perform bilinear interpolation of 20m bands to 10m spatial resolution for all 20m bands of the tile (You could use [Rasterio](https://rasterio.readthedocs.io/en/stable/topics/resampling.html))\n",
    "\n",
    "- Divide the tile into non-overlapping patches of size **120 x 120 pixels**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943031e8-fe63-4117-bd57-fa739bc21a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd05440-235f-43c9-8ef9-86ba667e17a9",
   "metadata": {},
   "source": [
    "## 3.2 Change detection\n",
    "### 3.2.1 NDVI and CNN Mask Calculation\n",
    "\n",
    "For each extracted patch compute:\n",
    "\n",
    " a. NDVI\n",
    " \n",
    " b. CNN Mask\n",
    "    - Apply the CNN segmentation model from Task 2 to each patch. (**Note:** don't forget to preprocess)\n",
    "    \n",
    "To convert it into a binary mask, find a good threshhold. Argue your choice for the NDVI and CNN in a short paragraph.\n",
    "\n",
    "### 3.2.2 Change Detection and Forest Loss Computation\n",
    "\n",
    "For both NDVI and CNN masks compute for the full tile (all patches):\n",
    "\n",
    "- **Percentage loss:**  \n",
    "  percentage_loss = 100 * (forest_pixels_2018 - forest_pixels_2024) / forest_pixels_2018\n",
    "\n",
    "- **Absolute loss (m²):**  \n",
    "  absolute_loss = (forest_pixels_2018 - forest_pixels_2024) * 100\n",
    "\n",
    "where `forest_pixels_2018` and `forest_pixels_2024` are the number of forest pixels in 2018 and 2024, respectively. Each pixel represents 100 m² (10m resolution).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3d158d-6fbc-4385-8f02-50bded553dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here goes some code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b5140b-a05c-4ad6-9b16-328ba79bae32",
   "metadata": {},
   "source": [
    "**TODO:** Describe the results in a few paragraphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fd8584-2f84-4487-8a82-5f309495cfe4",
   "metadata": {},
   "source": [
    "## 3.3 Extensive Qualitative Analysis\n",
    "\n",
    "Select six representative patches:\n",
    "\n",
    "- Two patches with high loss.\n",
    "- Two patches with minimal or no loss.\n",
    "- Two patches with interesting discrepancies between methods.\n",
    "\n",
    "For each patch plot:\n",
    "\n",
    "- RGB composite for 2018 and 2024.\n",
    "- CNN mask for 2018 and 2024.\n",
    "- NDVI mask for 2018 and 2024.\n",
    "\n",
    "Annotate each visualization with the computed percentage loss for both NDVI and CNN.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e91b5b-fb8c-42b7-8439-d116f79d17db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here go some plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f9f6f1-98e8-4583-8cd2-0fd683b5379b",
   "metadata": {},
   "source": [
    "## 3.4 Method Comparison and Interpretation\n",
    "\n",
    "Write a detailed qualitative evaluation (~500 words) discussing:\n",
    "\n",
    "- Describe your plots.\n",
    "- Which method performed more robustly across varying conditions. Why?\n",
    "- Sensitivity to atmospheric noise, and classification errors.\n",
    "- Advantages and limitations of both approaches.\n",
    "- Possible improvements of both methods.\n",
    "- Which method you would recommend for systematic deforestation assessment.\n",
    "- Further remarks/ observations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a84576d-4af0-4007-8e62-6deb7f8592bd",
   "metadata": {},
   "source": [
    "**TODO:** Describe the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
