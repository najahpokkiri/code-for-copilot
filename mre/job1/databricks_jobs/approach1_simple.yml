# ============================================================================
# APPROACH 1: Simple Hardcoded Paths (NOT RECOMMENDED)
# ============================================================================
#
# Pros:
#   ✓ Easy to understand
#   ✓ Works immediately
#
# Cons:
#   ✗ Hardcoded paths need manual updates
#   ✗ Not portable between environments
#   ✗ Needs code changes for different users/projects
#
# Use when:
#   - Quick testing
#   - Single environment only
#   - Paths will never change
#
# ============================================================================

resources:
  jobs:
    geospatial_pipeline_ind:
      name: Geospatial Pipeline - IND
      description: |
        GHSL building enrichment pipeline for India

        Generates 2km grid building estimates with TSI calculations

        Tasks:
          0. Generate config from YAML
          1. Load proportions/TSI to Delta
          2. Generate 2km grid
          3. Download GHSL tiles
          4. Extract raster statistics
          5. Post-processing & TSI
          6. Create per-LOB views
          7. Export CSV + Excel

      queue:
        enabled: true

      tasks:
        # ========================================================================
        # TASK 0: Generate Configuration
        # ========================================================================
        - task_key: task0_generate_config
          description: Generate config.json from config.yaml
          spark_python_task:
            python_file: /Workspace/Users/npokkiri@munichre.com/geospatial_pipeline/task0_generate_config.py
            parameters:
              - --config_yaml_path
              - /Workspace/Users/npokkiri@munichre.com/geospatial_pipeline/config.yaml
              - --output_path
              - /Workspace/Users/npokkiri@munichre.com/geospatial_pipeline/config.json
          existing_cluster_id: 1010-130900-1bz314p1

        # ========================================================================
        # TASK 1: Load Proportions
        # ========================================================================
        - task_key: task1_proportions_to_delta
          description: Load proportions and TSI CSVs to Delta tables
          depends_on:
            - task_key: task0_generate_config
          spark_python_task:
            python_file: /Workspace/Users/npokkiri@munichre.com/geospatial_pipeline/task1_proportions_to_delta.py
            parameters:
              - --config_path
              - /Workspace/Users/npokkiri@munichre.com/geospatial_pipeline/config.json
          existing_cluster_id: 1010-130900-1bz314p1

        # ========================================================================
        # TASK 2: Grid Generation
        # ========================================================================
        - task_key: task2_grid_generation
          description: Generate 2km grid centroids for country
          depends_on:
            - task_key: task1_proportions_to_delta
          spark_python_task:
            python_file: /Workspace/Users/npokkiri@munichre.com/geospatial_pipeline/task2_grid_generation.py
            parameters:
              - --config_path
              - /Workspace/Users/npokkiri@munichre.com/geospatial_pipeline/config.json
          existing_cluster_id: 1010-130900-1bz314p1
          libraries:
            - pypi:
                package: rasterio==1.3.9
            - pypi:
                package: geopandas==0.14.4
            - pypi:
                package: shapely==2.0.4

        # ========================================================================
        # TASK 3: Download Tiles
        # ========================================================================
        - task_key: task3_tile_downloader
          description: Download GHSL tiles from JRC repository
          depends_on:
            - task_key: task2_grid_generation
          spark_python_task:
            python_file: /Workspace/Users/npokkiri@munichre.com/geospatial_pipeline/task3_tile_downloader.py
            parameters:
              - --config_path
              - /Workspace/Users/npokkiri@munichre.com/geospatial_pipeline/config.json
          existing_cluster_id: 1010-130900-1bz314p1

        # ========================================================================
        # TASK 4: Raster Statistics
        # ========================================================================
        - task_key: task4_raster_stats
          description: Extract building counts from raster tiles
          depends_on:
            - task_key: task3_tile_downloader
          spark_python_task:
            python_file: /Workspace/Users/npokkiri@munichre.com/geospatial_pipeline/task4_raster_stats.py
            parameters:
              - --config_path
              - /Workspace/Users/npokkiri@munichre.com/geospatial_pipeline/config.json
          existing_cluster_id: 1010-130900-1bz314p1
          libraries:
            - pypi:
                package: rasterio==1.3.9

        # ========================================================================
        # TASK 5: Post-Processing
        # ========================================================================
        - task_key: task5_post_processing
          description: Process counts and calculate TSI
          depends_on:
            - task_key: task4_raster_stats
          spark_python_task:
            python_file: /Workspace/Users/npokkiri@munichre.com/geospatial_pipeline/task5_post_processing.py
            parameters:
              - --config_path
              - /Workspace/Users/npokkiri@munichre.com/geospatial_pipeline/config.json
          existing_cluster_id: 1010-130900-1bz314p1

        # ========================================================================
        # TASK 6: Create Views
        # ========================================================================
        - task_key: task6_create_views
          description: Create per-LOB TSI proportion views
          depends_on:
            - task_key: task5_post_processing
          spark_python_task:
            python_file: /Workspace/Users/npokkiri@munichre.com/geospatial_pipeline/task6_create_views.py
            parameters:
              - --config_path
              - /Workspace/Users/npokkiri@munichre.com/geospatial_pipeline/config.json
          existing_cluster_id: 1010-130900-1bz314p1

        # ========================================================================
        # TASK 7: Export
        # ========================================================================
        - task_key: task7_export
          description: Export CSV files and Excel summary
          depends_on:
            - task_key: task6_create_views
          spark_python_task:
            python_file: /Workspace/Users/npokkiri@munichre.com/geospatial_pipeline/task7_export.py
            parameters:
              - --config_path
              - /Workspace/Users/npokkiri@munichre.com/geospatial_pipeline/config.json
          existing_cluster_id: 1010-130900-1bz314p1
          libraries:
            - pypi:
                package: xlsxwriter==3.2.9

# ============================================================================
# DEPLOYMENT INSTRUCTIONS
# ============================================================================
#
# 1. Update all paths to match your Workspace location
# 2. Update cluster_id to your cluster
# 3. Deploy via Databricks CLI:
#    databricks jobs create --json-file approach1_simple.yml
#
# Or via UI:
#    - Copy this YAML
#    - Go to Workflows > Create Job
#    - Switch to YAML view
#    - Paste and save
#
# ============================================================================
